<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="js/commons.js"></script>
  <script src="js/faceDetectionControls.js"></script>
  <script src="js/imageSelectionControls.js"></script>
  <script src="js/bbt.js"></script>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
</head>
<body>
  <div id="navbar"></div>
  <div class="center-content page-container">

    <div class="progress" id="loader">
      <div class="indeterminate"></div>
    </div>
    <div style="position: relative" class="margin">
      <img id="inputImg" src="" style="max-width: 800px;" />
      <canvas id="overlay" />
    </div>
    

    <div style="position: relative" class="margin">
      <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay muted></video>
      <button  class="waves-effect waves-light btn" onclick="startRollcall()">  <i class="material-icons left">开始点名</i> </button>        
      <button  class="waves-effect waves-light btn" onclick="stopRollcall()"> <i class="material-icons left">结束点名</i></button>        
    </div>

    <div style="position: relative" class="margin">      
      <button  class="waves-effect waves-light btn" onclick="extractPhoto()">  <i class="material-icons left">选择要被点名的人</i> </button>              
    </div>

    <label for="facesContainer">演示从照片中得到要被点名的人</label>
    <div id="facesContainer"></div>

    <div class="row side-by-side">
      <!-- face_detector_selection_control -->
      <div id="face_detector_selection_control" class="row input-field" style="margin-right: 20px;">
        <select id="selectFaceDetector">
          <option value="ssd_mobilenetv1">SSD Mobilenet V1</option>
          <option value="tiny_face_detector">Tiny Face Detector</option>
          <option value="mtcnn">MTCNN</option>
        </select>
        <label>Select Face Detector</label>
      </div>
      <!-- face_detector_selection_control -->

      <!-- image_selection_control -->
      <div id="image_selection_control"></div>
        <div id="selectList"></div>
        <div class="row">
          <label for="imgUrlInput">Get image from URL:</label>
          <input id="imgUrlInput" type="text" class="bold">
        </div>
        <button
          class="waves-effect waves-light btn"
          onclick="loadImageFromUrl()"
        >
          Ok
        </button>
      <div id="image_selection_control"></div>
      <!-- image_selection_control -->

    </div>

    <!-- ssd_mobilenetv1_controls -->
    <span id="ssd_mobilenetv1_controls">
      <div class="row side-by-side">
        <div class="row">
          <label for="attendeesList">点名结果</label>                              
          <input disabled value="100" id="attendeesList" type="text" class="bold">          
        </div>        
      </div>
    </span>
    <!-- ssd_mobilenetv1_controls -->

    <!-- tiny_face_detector_controls -->
    <span id="tiny_face_detector_controls">
      <div class="row side-by-side">
        <div class="row input-field" style="margin-right: 20px;">
          <select id="inputSize">
            <option value="" disabled selected>Input Size:</option>
            <option value="160">160 x 160</option>
            <option value="224">224 x 224</option>
            <option value="320">320 x 320</option>
            <option value="416">416 x 416</option>
            <option value="512">512 x 512</option>
            <option value="608">608 x 608</option>
          </select>
          <label>Input Size</label>
        </div>
        <div class="row">
          <label for="scoreThreshold">Score Threshold:</label>
          <input disabled value="0.5" id="scoreThreshold" type="text" class="bold">
        </div>
        <button
          class="waves-effect waves-light btn"
          onclick="onDecreaseScoreThreshold()"
        >
          <i class="material-icons left">-</i>
        </button>
        <button
          class="waves-effect waves-light btn"
          onclick="onIncreaseScoreThreshold()"
        >
          <i class="material-icons left">+</i>
        </button>
      </div>
    </span>
    <!-- tiny_face_detector_controls -->

    <!-- mtcnn_controls -->
    <span id="mtcnn_controls">
      <div class="row side-by-side">
        <div class="row">
          <label for="minFaceSize">Minimum Face Size:</label>
          <input disabled value="20" id="minFaceSize" type="text" class="bold">
        </div>
        <button
          class="waves-effect waves-light btn"
          onclick="onDecreaseMinFaceSize()"
        >
          <i class="material-icons left">-</i>
        </button>
        <button
          class="waves-effect waves-light btn"
          onclick="onIncreaseMinFaceSize()"
        >
          <i class="material-icons left">+</i>
        </button>
      </div>
    </span>
    <!-- mtcnn_controls -->

  </body>

  <script>
    let faceMatcher = null
    let roll_calling = true
    let attendees = new Set()
    let g_detections = new Array
    let g_faceImages = new Array


    async function updateResults() {
      if (!roll_calling)
        return

      if (!isFaceDetectionModelLoaded()) {
        return
      }

      const inputImgEl = $('#inputImg').get(0)
     
      const videoEl = $('#inputVideo').get(0)
      if(videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
       return setTimeout(() => updateResults())
    
console.log("start to detect.")
      const options = getFaceDetectorOptions()
      const results = await faceapi
        //.detectAllFaces(inputImgEl, options)
        .detectAllFaces(videoEl, options)
        .withFaceLandmarks()
        .withFaceDescriptors()

console.log("start to match and draw.")
console.log(results.length)

      drawFaceRecognitionResults(results)

      setTimeout(() => updateResults(), 1000)
    }

    //match and draw
    function drawFaceRecognitionResults(results) {
      const canvas = $('#overlay').get(0)
      const inputImgEl = $('#inputImg').get(0)

      faceapi.matchDimensions(canvas, inputImgEl)
      // resize detection and landmarks in case displayed image is smaller than
      // original size
      const resizedResults = faceapi.resizeResults(results, inputImgEl)

      resizedResults.forEach(({ detection, descriptor }) => {
        const bestMatch = faceMatcher.findBestMatch(descriptor)
        const label = bestMatch.toString()
        const options = { label }


        if (bestMatch.label != "unknown") {
          attendees.add(bestMatch.label)
  
          let al = "";
          for (a of attendees) {
            al += a + "; "
          }         
          $('#attendeesList').val(al)      
        }

        //const drawBox = new faceapi.draw.DrawBox(detection.box, options)
        //drawBox.draw(canvas)
      })
    }

    async function startRollcall() {
      // start processing image
      roll_calling = true;
      updateResults()
    }
    async function stopRollcall() {
      roll_calling = false;
    }
    
    async function onPlay() {
      return
      const videoEl = $('#inputVideo').get(0)

      if(videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
        return setTimeout(() => onPlay())

        
/*
      const options = getFaceDetectorOptions()

      const ts = Date.now()

   //   const result = await faceapi.detectSingleFace(videoEl, options)
      //const result = await faceapi.detectAllFaces(videoEl, options)

///      updateTimeStats(Date.now() - ts)

      if (result) {
        const canvas = $('#overlay').get(0)
        const dims = faceapi.matchDimensions(canvas, videoEl, true)
        faceapi.draw.drawDetections(canvas, faceapi.resizeResults(result, dims))
      }
*/
      setTimeout(() => onPlay())
    }


///// for extract photo
    async function extractPhoto() {
      if (!isFaceDetectionModelLoaded()) {
        return
      }

      const videoEl = $('#inputVideo').get(0)
      if(videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
       return setTimeout(() => extractPhoto())

      const inputImgEl = $('#inputImg').get(0)
      const options = getFaceDetectorOptions()

      const detections = await faceapi.detectAllFaces(videoEl, options)
      const faceImages = await faceapi.extractFaces(videoEl, detections)

      g_detections = g_detections.concat(detections)
      g_faceImages = g_faceImages.concat(faceImages)

      displayExtractedFaces(g_faceImages)
    }
    function displayExtractedFaces(faceImages) {
      $('#facesContainer').empty()
      faceImages.forEach(canvas => $('#facesContainer').append(canvas))
    }


    async function run() {
      // load face detection, face landmark model and face recognition models
      await changeFaceDetector(selectedFaceDetector)
      await faceapi.loadFaceLandmarkModel('/')
      await faceapi.loadFaceRecognitionModel('/')

      // initialize face matcher with 1 reference descriptor per bbt character
      faceMatcher = await createBbtFaceMatcher(1)

// await changeFaceDetector(TINY_FACE_DETECTOR)
//      changeInputSize(128)

      // try to access users webcam and stream the images to the video element      
      ///need https
      const stream = await navigator.mediaDevices.getUserMedia({ video: true })      
      const videoEl = $('#inputVideo').get(0)
      videoEl.srcObject = stream

    }

    $(document).ready(function() {
      renderNavBar('#navbar', 'bbt_face_recognition')
      initImageSelectionControls()
      initFaceDetectionControls()
      run()
    })
  </script>
</body>
</html>